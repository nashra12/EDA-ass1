{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1897b77c-c0f0-43db-87cc-f1da0d768c8c",
   "metadata": {},
   "source": [
    "Q1. What are the key features of the wine quality data set? Discuss the importance of each feature in\n",
    "predicting the quality of wine.\n",
    "Ans-> 1)Fixed Acidity\n",
    "2)Volatile Acidity\n",
    "3)Citric Acid\n",
    "4)Residual sugar\n",
    "5)Chlorides\n",
    "6)Free Sulfur Dioxide\n",
    "7)Total Sulfur Dioxide\n",
    "8)Density\n",
    "9)Ph\n",
    "10)Sulphates\n",
    "11)Alcohol\n",
    "12)Quality\n",
    "\n",
    "\n",
    "Importance of Each Feature in Predicting Wine Quality\n",
    "\n",
    "Fixed Acidity and Volatile Acidity: These features directly influence the taste balance and the perceived sharpness or softness of the wine. \n",
    "\n",
    "Citric Acid: Adds freshness and complexity.\n",
    "\n",
    "Residual Sugar: A key determinant of sweetness.\n",
    "\n",
    "Chlorides: While not a major component, elevated levels can indicate quality issues, thus affecting the quality score.\n",
    "\n",
    "Sulfur Dioxide (Free and Total): Essential for preservation but must be balanced to avoid negative sensory impacts and meet regulatory standards.\n",
    "\n",
    " Density: Provides indirect information about alcohol and sugar content, which are significant for the wine's body and mouthfeel.\n",
    "\n",
    " pH: Influences microbial stability and aging potential, playing a critical role in the wine's taste and preservation.\n",
    "\n",
    " Sulphates: Helps in preserving wine quality and enhancing flavors, but must be managed to avoid bitterness.\n",
    "\n",
    "Alcohol: Significant for the overall body, flavor complexity, and mouthfeel. A balanced alcohol content is essential for quality perception.\n",
    "\n",
    "\n",
    "\n",
    "Q2. How did you handle missing data in the wine quality data set during the feature engineering process?\n",
    "Discuss the advantages and disadvantages of different imputation techniques.\n",
    "Ans->data_cleaned = data.dropna()\n",
    "Simple and easy to implement.\n",
    "No assumptions made about the missing data.\n",
    "\n",
    "Fill Missing Values with Mean/Median/Mode\n",
    "data['feature'] = data['feature'].fillna(data['feature'].mean())  # Mean\n",
    "data['feature'] = data['feature'].fillna(data['feature'].median())  # Median\n",
    "data['feature'] = data['feature'].fillna(data['feature'].mode()[0])  # Mode\n",
    "\n",
    "Advantages:\n",
    "\n",
    "    Easy to implement.\n",
    "Disadvantages:\n",
    "\n",
    "    Can introduce bias\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "Q3. What are the key factors that affect students' performance in exams? How would you go about\n",
    "analyzing these factors using statistical techniques?\n",
    "Ans->Statistical Techniques\n",
    "\n",
    "    Descriptive Statistics:\n",
    "        Mean, median, mode, standard deviation, variance to summarize data.\n",
    "\n",
    "    Correlation Analysis:\n",
    "        Pearson or Spearman correlation to assess the strength of relationships between variables.\n",
    "Q4. Describe the process of feature engineering in the context of the student performance data set. How\n",
    "did you select and transform the variables for your model?\n",
    "\n",
    "Ans->1. Understanding the Dataset\n",
    "\n",
    "    Explore Data: Begin by understanding the structure of the dataset (student_performance.csv), including the columns, data types, and any missing values.\n",
    "    Domain Knowledge: Gain insights into how each variable (feature) might influence students' academic performance.\n",
    "\n",
    "2. Feature Selection\n",
    "\n",
    "    Correlation Analysis\n",
    "Feature Creation\n",
    "Handling Missing Data\n",
    "Normalization and Scaling\n",
    "Feature Selection Techniques\n",
    "\n",
    "\n",
    "\n",
    "Q5. Load the wine quality data set and perform exploratory data analysis (EDA) to identify the distribution\n",
    "of each feature. Which feature(s) exhibit non-normality, and what transformations could be applied to\n",
    "these features to improve normality?\n",
    "\n",
    "\n",
    "Ans-> import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# EDA: Histograms of all features\n",
    "df.hist(figsize=(12, 10), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify non-normal features\n",
    "non_normal_features = ['alcohol', 'density']\n",
    "\n",
    "# Apply transformations\n",
    "df['log_alcohol'] = np.log(df['alcohol'] + 1)  # Log transformation\n",
    "df['sqrt_density'] = np.sqrt(df['density'])   # Square root transformation\n",
    "df['boxcox_density'], _ = boxcox(df['density'] + 1)  # Box-Cox transformation\n",
    "\n",
    "\n",
    "Q6. Using the wine quality data set, perform principal component analysis (PCA) to reduce the number of\n",
    "features. What is the minimum number of principal components required to explain 90% of the variance in\n",
    "the data?\n",
    "Ans-> import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the wine quality dataset (assuming red wine dataset for example)\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "# Separate features (X) and target (y), if applicable\n",
    "X = df.drop(columns=['quality'])  # Assuming 'quality' is the target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Calculate explained variance ratio and cumulative variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Determine the number of components explaining 90% of variance\n",
    "n_components_90 = np.argmax(cumulative_variance_ratio >= 0.90) + 1  # +1 because of zero-indexing\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of components explaining 90% of variance: {n_components_90}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0154602e-8a2c-4e32-9da3-e5d6ebc2988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components explaining 90% of variance: 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the wine quality dataset (assuming red wine dataset for example)\n",
    "df = pd.read_csv('wineQualityReds.csv')\n",
    "\n",
    "# Separate features (X) and target (y), if applicable\n",
    "X = df.drop(columns=['quality'])  # Assuming 'quality' is the target variable\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Calculate explained variance ratio and cumulative variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Determine the number of components explaining 90% of variance\n",
    "n_components_90 = np.argmax(cumulative_variance_ratio >= 0.90) + 1  # +1 because of zero-indexing\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of components explaining 90% of variance: {n_components_90}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96809281-9180-4dc0-b8f8-12887dcea1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
